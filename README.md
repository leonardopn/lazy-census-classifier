# lazy-census-classifier - Classificador de Renda com Racioc√≠nio Baseado em Casos (CBR)

Este projeto √© um classificador de aprendizado de m√°quina desenvolvido como parte da disciplina de P√≥s-Gradua√ß√£o em Aprendizado de M√°quina. O sistema utiliza a abordagem de Racioc√≠nio Baseado em Casos (CBR), um paradigma de _Lazy Learning_, para prever se a renda anual de um indiv√≠duo excede $50.000 com base em dados demogr√°ficos do censo.

O prot√≥tipo foi implementado em Python utilizando a biblioteca `cbrkit` e foca na aplica√ß√£o de conceitos te√≥ricos de CBR, como a constru√ß√£o de fun√ß√µes de similaridade h√≠bridas, pondera√ß√£o de atributos e otimiza√ß√£o do re√∫so com k-NN.

## üéØ Objetivo

O objetivo principal do trabalho √© construir um sistema CBR funcional que cumpra as etapas de **Recupera√ß√£o** e **Re√∫so** do ciclo CBR. A performance do sistema √© validada objetivamente atrav√©s do m√©todo de teste **Leave-One-Out Cross-Validation (LOOCV)**, conforme especificado nos requisitos da disciplina.

## ‚ú® Principais Funcionalidades

O sistema implementa v√°rias t√©cnicas para otimizar a precis√£o da classifica√ß√£o:

-   **Similaridade H√≠brida:** Utiliza diferentes fun√ß√µes de similaridade locais para cada tipo de atributo, combinando `similaridade linear` para dados num√©ricos (ex: idade) e `similaridade de igualdade` para dados categ√≥ricos (ex: escolaridade).
-   **Pondera√ß√£o de Atributos:** Aplica uma m√©dia ponderada para agregar as similaridades locais, permitindo que atributos mais relevantes (como `education` e `occupation`) tenham maior influ√™ncia no resultado final.
-   **Re√∫so com k-NN (k-Nearest Neighbors):** Em vez de usar apenas o caso mais similar (1-NN), o sistema recupera os `k` vizinhos mais pr√≥ximos e realiza uma vota√ß√£o majorit√°ria para determinar a classe final, tornando o classificador mais robusto a ru√≠dos.
-   **Avalia√ß√£o Paralelizada:** O teste de performance com _Leave-One-Out_ √© executado em paralelo utilizando `concurrent.futures`, acelerando significativamente o processo de valida√ß√£o.

## üìä Dataset

O projeto utiliza o dataset [**"Adult Census Income"**](https://www.kaggle.com/datasets/mosapabdelghany/adult-income-prediction-dataset), obtido do reposit√≥rio UCI Machine Learning. Ele cont√©m informa√ß√µes demogr√°ficas de mais de 30.000 indiv√≠duos e o objetivo √© classificar a coluna `income` em uma de duas categorias: `<=50K` ou `>50K`.

O CSV com os dados est√° localizado na pasta `datasets`.

## üõ†Ô∏è Tecnologias Utilizadas

-   **Linguagem:** Python 3.12+
-   **Biblioteca CBR:** `cbrkit`
-   **Manipula√ß√£o de Dados:** `pandas`
-   **Execu√ß√£o Paralela:** `concurrent.futures`
-   **Desenvolvimento:** `watchfiles` para recarregamento autom√°tico

## üöÄ Como Executar

1.  **Clone o reposit√≥rio:**

    ```bash
    git clone https://github.com/leonardopn/lazy-census-classifier
    cd lazy-census-classifier
    ```

2.  **Instale as depend√™ncias:**
    _O projeto utiliza [`uv`](https://docs.astral.sh/uv/) para gerenciamento de pacotes. [Clique aqui ](https://docs.astral.sh/uv/) para baixar o uv se for necess√°rio._

    ```bash
    uv run main.py
    ```

## üìà Resultados e An√°lise de Performance

Para validar a efic√°cia do classificador e o impacto das otimiza√ß√µes, foi conduzida uma s√©rie de testes utilizando o m√©todo _Leave-One-Out_ em uma amostra de 500 casos. As estrat√©gias testadas inclu√≠ram a pondera√ß√£o de atributos e a varia√ß√£o do n√∫mero de vizinhos (k) no algoritmo k-NN.

### Resumo dos Resultados

A an√°lise dos testes revela uma jornada clara de otimiza√ß√£o:

1.  **Impacto do k-NN:** A mudan√ßa de um classificador 1-NN para um 5-NN (Teste 1 vs. Teste 3) resultou no ganho de performance mais significativo, com um salto de **19 acertos**, provando que o sistema se torna mais robusto ao considerar m√∫ltiplos vizinhos para a vota√ß√£o da classe.
2.  **Efic√°cia da Pondera√ß√£o:** A aplica√ß√£o de pesos nos atributos consistentemente melhorou ou manteve a acur√°cia do modelo. O maior ganho com esta t√©cnica foi observado no modelo 10-NN (Teste 5 vs. Teste 6), com um aumento de **4 acertos**, o que levou o sistema ao seu pico de performance.
3.  **Ponto √ìtimo de Performance:** Os testes indicam que o ponto ideal para o modelo foi alcan√ßado com **k=10 e com pesos**, atingindo **419 acertos** e uma acur√°cia m√°xima de **83.80%**.
4.  **In√≠cio da Perda (Overfitting):** Ao aumentar o n√∫mero de vizinhos para k=15, a performance come√ßou a decair. Isso sugere que a "vizinhan√ßa" se tornou muito ampla, incluindo casos menos relevantes na vota√ß√£o e diminuindo a capacidade de generaliza√ß√£o do modelo.

### Tabela Comparativa de Resultados

| Estrat√©gia do Teste            |                  N¬∫ de Acertos (de 500)                  |                          Acur√°cia                           |                   Melhora (vs. anterior)                    |
| ------------------------------ | :------------------------------------------------------: | :---------------------------------------------------------: | :---------------------------------------------------------: |
| Teste 1 (1-NN, sem pesos)      |                           391                            |                           78.20%                            |                              -                              |
| Teste 2 (1-NN, **com** pesos)  |                           393                            |                           78.60%                            |                           +0.40%                            |
| Teste 3 (5-NN, sem pesos)      |                           410                            |                           82.00%                            | <span style="color:green;font-weight:bold">üëë +3.40%</span> |
| Teste 4 (5-NN, **com** pesos)  |                           410                            |                           82.00%                            |                           +0.00%                            |
| Teste 5 (10-NN, sem pesos)     |                           415                            |                           83.00%                            |                           +1.00%                            |
| Teste 6 (10-NN, **com** pesos) | <span style="color:green;font-weight:bold">üëë 419</span> | <span style="color:green;font-weight:bold">üëë 83.80%</span> |                           +0.80%                            |
| Teste 7 (15-NN, sem pesos)     |                           415                            |                           83.00%                            |  <span style="color:red;font-weight:bold">üëé -0.80%</span>  |
| Teste 8 (15-NN, **com** pesos) |                           415                            |                           83.00%                            |                            0.00%                            |
